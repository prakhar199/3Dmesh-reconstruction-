{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd70b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn,optim\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d70f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./samples/sample_data.json') as f:\n",
    "    x = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a52b6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'length_start': 3388, 'length_end': 3217, 'width_start': 3351, 'width_end': 3349, 'height_start': 3353, 'height_end': 3324}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from star.pytorch.star import STAR\n",
    "\n",
    "with open ('idx_data.txt', 'rb') as fr:\n",
    "    idx_data = pickle.load(fr)\n",
    "    \n",
    "print(idx_data)\n",
    "\n",
    "length_start_idx = idx_data['length_start']\n",
    "length_end_idx = idx_data['length_end']\n",
    "width_start_idx = idx_data['width_start']\n",
    "width_end_idx = idx_data['width_end']\n",
    "height_start_idx = idx_data['height_start']\n",
    "height_end_idx = idx_data['height_end']\n",
    "\n",
    "sample_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a91a158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/789766872.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_x2 = torch.tensor(train_x1)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/789766872.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_y2 = torch.tensor(train_y1).reshape(800,300)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/789766872.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_x2 = torch.tensor(test_x1)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/789766872.py:117: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_y2 = torch.tensor(test_y1).reshape(200,300)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/789766872.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_x3 = torch.tensor(train_x1)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/789766872.py:120: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_y3 = torch.tensor(train_y1).reshape(800,300)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/789766872.py:121: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_x3 = torch.tensor(test_x1)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/789766872.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_y3 = torch.tensor(test_y1).reshape(200,300)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/789766872.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_x4 = torch.tensor(train_x1)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/789766872.py:125: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_y4 = torch.tensor(train_y1).reshape(800,300)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/789766872.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_x4 = torch.tensor(test_x1)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/789766872.py:127: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_y4 = torch.tensor(test_y1).reshape(200,300)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/789766872.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_x5 = torch.tensor(train_x1)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/789766872.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_y5 = torch.tensor(train_y1).reshape(800,300)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/789766872.py:131: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_x5 = torch.tensor(test_x1)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/789766872.py:132: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_y5 = torch.tensor(test_y1).reshape(200,300)\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "train_x1 = []\n",
    "train_y1 = []\n",
    "test_x1 = []\n",
    "test_y1 = []\n",
    "\n",
    "train_x2 = []\n",
    "train_y2 = []\n",
    "test_x2 = []\n",
    "test_y2 = []\n",
    "\n",
    "train_x3 = []\n",
    "train_y3 = []\n",
    "test_x3 = []\n",
    "test_y3 = []\n",
    "\n",
    "train_x4 = []\n",
    "train_y4 = []\n",
    "test_x4 = []\n",
    "test_y4 = []\n",
    "\n",
    "train_x5 = []\n",
    "train_y5 = []\n",
    "test_x5 = []\n",
    "test_y5 = []\n",
    "\n",
    "for case in x:\n",
    "    if num < 200:\n",
    "        test_x1.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        test_y1.append(case['shape']) \n",
    "        \n",
    "        train_x2.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y2.append(case['shape']) \n",
    "        \n",
    "        train_x3.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y3.append(case['shape']) \n",
    "        \n",
    "        train_x4.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y4.append(case['shape']) \n",
    "        \n",
    "        train_x5.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y5.append(case['shape']) \n",
    "        \n",
    "    elif num < 400:\n",
    "        train_x1.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y1.append(case['shape'])  \n",
    "        \n",
    "        test_x2.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        test_y2.append(case['shape']) \n",
    "        \n",
    "        train_x3.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y3.append(case['shape']) \n",
    "        \n",
    "        train_x4.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y4.append(case['shape']) \n",
    "        \n",
    "        train_x5.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y5.append(case['shape']) \n",
    "        \n",
    "    elif num < 600:\n",
    "        train_x1.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y1.append(case['shape'])  \n",
    "        \n",
    "        train_x2.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y2.append(case['shape']) \n",
    "        \n",
    "        test_x3.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        test_y3.append(case['shape']) \n",
    "        \n",
    "        train_x4.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y4.append(case['shape']) \n",
    "        \n",
    "        train_x5.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y5.append(case['shape']) \n",
    "        \n",
    "    elif num < 800:\n",
    "        train_x1.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y1.append(case['shape']) \n",
    "        \n",
    "        train_x2.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y2.append(case['shape']) \n",
    "        \n",
    "        train_x3.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y3.append(case['shape']) \n",
    "        \n",
    "        test_x4.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        test_y4.append(case['shape']) \n",
    "        \n",
    "        train_x5.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y5.append(case['shape']) \n",
    "        \n",
    "    elif num < 1000:\n",
    "        train_x1.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y1.append(case['shape'])  \n",
    "        \n",
    "        train_x2.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y2.append(case['shape']) \n",
    "        \n",
    "        train_x3.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y3.append(case['shape']) \n",
    "        \n",
    "        train_x4.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y4.append(case['shape']) \n",
    "        \n",
    "        test_x5.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        test_y5.append(case['shape']) \n",
    "    num+=1 \n",
    "\n",
    "train_x1 = torch.tensor(train_x1)\n",
    "train_y1 = torch.tensor(train_y1).reshape(800,300)\n",
    "test_x1 = torch.tensor(test_x1)\n",
    "test_y1 = torch.tensor(test_y1).reshape(200,300)\n",
    "\n",
    "train_x2 = torch.tensor(train_x1)\n",
    "train_y2 = torch.tensor(train_y1).reshape(800,300)\n",
    "test_x2 = torch.tensor(test_x1)\n",
    "test_y2 = torch.tensor(test_y1).reshape(200,300)\n",
    "\n",
    "train_x3 = torch.tensor(train_x1)\n",
    "train_y3 = torch.tensor(train_y1).reshape(800,300)\n",
    "test_x3 = torch.tensor(test_x1)\n",
    "test_y3 = torch.tensor(test_y1).reshape(200,300)\n",
    "\n",
    "train_x4 = torch.tensor(train_x1)\n",
    "train_y4 = torch.tensor(train_y1).reshape(800,300)\n",
    "test_x4 = torch.tensor(test_x1)\n",
    "test_y4 = torch.tensor(test_y1).reshape(200,300)\n",
    "\n",
    "train_x5 = torch.tensor(train_x1)\n",
    "train_y5 = torch.tensor(train_y1).reshape(800,300)\n",
    "test_x5 = torch.tensor(test_x1)\n",
    "test_y5 = torch.tensor(test_y1).reshape(200,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201b6987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Data1(Dataset):\n",
    "    def __init__(self):\n",
    "            self.x=train_x1\n",
    "            self.w=torch.zeros(3,300)\n",
    "            self.b=torch.zeros(800,300)\n",
    "            self.f=torch.mm(self.x,self.w)+self.b\n",
    "            \n",
    "            self.y=train_y1\n",
    "            self.len=self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "class Data2(Dataset):\n",
    "    def __init__(self):\n",
    "            self.x=train_x2\n",
    "            self.w=torch.zeros(3,300)\n",
    "            self.b=torch.zeros(800,300)\n",
    "            self.f=torch.mm(self.x,self.w)+self.b\n",
    "            \n",
    "            self.y=train_y2\n",
    "            self.len=self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "class Data3(Dataset):\n",
    "    def __init__(self):\n",
    "            self.x=train_x3\n",
    "            self.w=torch.zeros(3,300)\n",
    "            self.b=torch.zeros(800,300)\n",
    "            self.f=torch.mm(self.x,self.w)+self.b\n",
    "            \n",
    "            self.y=train_y3\n",
    "            self.len=self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "class Data4(Dataset):\n",
    "    def __init__(self):\n",
    "            self.x=train_x4\n",
    "            self.w=torch.zeros(3,300)\n",
    "            self.b=torch.zeros(800,300)\n",
    "            self.f=torch.mm(self.x,self.w)+self.b\n",
    "            \n",
    "            self.y=train_y4\n",
    "            self.len=self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "class Data5(Dataset):\n",
    "    def __init__(self):\n",
    "            self.x=train_x5\n",
    "            self.w=torch.zeros(3,300)\n",
    "            self.b=torch.zeros(800,300)\n",
    "            self.f=torch.mm(self.x,self.w)+self.b\n",
    "            \n",
    "            self.y=train_y5\n",
    "            self.len=self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cfe635a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_set=Data()'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''data_set=Data()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2884377",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_regression(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(linear_regression,self).__init__()\n",
    "        self.linear=nn.Linear(input_size,output_size)\n",
    "    def forward(self,x):\n",
    "        ythat=self.linear(x)\n",
    "        return ythat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "004fa47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = torch.nn.Linear(3,1000, bias = True)\n",
    "linear2 = torch.nn.Linear(1000,1000, bias = True)\n",
    "linear3 = torch.nn.Linear(1000,1000, bias = True)\n",
    "linear4 = torch.nn.Linear(1000,1000, bias = True)\n",
    "linear5 = torch.nn.Linear(1000,1000, bias = True)\n",
    "linear6 = torch.nn.Linear(1000,300, bias = True)\n",
    "relu = torch.nn.ReLU()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baaa6b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'optimizer = optim.SGD(model.parameters(), lr = 0.1)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''optimizer = optim.SGD(model.parameters(), lr = 0.1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8cd791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a306ead9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_loader=DataLoader(dataset=data_set,batch_size=1800, shuffle=True)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train_loader=DataLoader(dataset=data_set,batch_size=1800, shuffle=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15c5e00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LOSS=[]\\n \\nepochs=1000\\nfor epoch in range(epochs):\\n    for x,y in train_loader:\\n        prediction = model(x)\\n        #calculate loss        \\n        loss=criterion(prediction ,y)\\n        #store loss/cost \\n        LOSS.append(loss.item())\\n        #clear gradient \\n        optimizer.zero_grad()\\n        #Backward pass: compute gradient of the loss with respect to all the learnable parameters\\n        loss.backward()\\n        #the step function on an Optimizer makes an update to its parameters\\n        optimizer.step()\\n     \\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''LOSS=[]\n",
    " \n",
    "epochs=1000\n",
    "for epoch in range(epochs):\n",
    "    for x,y in train_loader:\n",
    "        prediction = model(x)\n",
    "        #calculate loss        \n",
    "        loss=criterion(prediction ,y)\n",
    "        #store loss/cost \n",
    "        LOSS.append(loss.item())\n",
    "        #clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        #Backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "        loss.backward()\n",
    "        #the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer.step()\n",
    "     \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc026509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plt.plot(LOSS)\\nplt.xlabel(\"iterations \")\\nplt.ylabel(\"Cost/total loss \")\\nplt.show()'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''plt.plot(LOSS)\n",
    "plt.xlabel(\"iterations \")\n",
    "plt.ylabel(\"Cost/total loss \")\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6870cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_betas = 300\n",
    "batch_size = 1\n",
    "poses = torch.FloatTensor(np.zeros((batch_size,72)))\n",
    "trans = torch.FloatTensor(np.zeros((batch_size,3)))\n",
    "\n",
    "def test(model, optimizer, x_test, y_test):\n",
    "    cost_sum = 0 \n",
    "    for x in x_test:\n",
    "        betas = model(x)\n",
    "        betas = torch.reshape(betas,(1,300))\n",
    "        mystar = STAR(gender='female',num_betas=num_betas)\n",
    "        mymodel = mystar.forward(poses , betas , trans)\n",
    "        shaped = mymodel.v_shaped[-1, :, :]\n",
    "\n",
    "        x_diff = shaped[3387][0]\n",
    "        y_diff = shaped[3387][1]\n",
    "        z_diff = shaped[3387][2]\n",
    "\n",
    "        length = (shaped[length_end_idx-1][2]-shaped[length_start_idx-1][2]).item()\n",
    "        width = (shaped[width_end_idx-1][0]-shaped[width_start_idx-1][0]).item()\n",
    "        height = (shaped[height_end_idx-1][1]-shaped[height_start_idx-1][1]).item()\n",
    "\n",
    "        prediction = torch.tensor([length, width, height])\n",
    "        \n",
    "        cost = criterion(prediction*100, x*100)\n",
    "        #print('cost',cost)\n",
    "        #print('prediction',prediction*100)\n",
    "        #print('x_test',x*100)\n",
    "        #print('\\n')\n",
    "        cost_sum += cost.item()\n",
    "    print('mean cost: ' , cost_sum / len(x_test))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "005c3509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test(model, optimizer, test_x, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece3265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader1=DataLoader(dataset=Data1(),batch_size=1800, shuffle=True)\n",
    "train_loader2=DataLoader(dataset=Data2(),batch_size=1800, shuffle=True)\n",
    "train_loader3=DataLoader(dataset=Data3(),batch_size=1800, shuffle=True)\n",
    "train_loader4=DataLoader(dataset=Data4(),batch_size=1800, shuffle=True)\n",
    "train_loader5=DataLoader(dataset=Data5(),batch_size=1800, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de3f4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_betas = 300\n",
    "batch_size = 1\n",
    "poses = torch.FloatTensor(np.zeros((batch_size,72)))\n",
    "trans = torch.FloatTensor(np.zeros((batch_size,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bad47062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st\n",
      "mean cost:  0.4163753814972006\n",
      "2nd\n",
      "mean cost:  0.41728633270133286\n",
      "3rd\n",
      "mean cost:  0.4208912799338577\n",
      "4th\n",
      "mean cost:  0.40670547240413724\n",
      "5th\n",
      "mean cost:  0.411596542163752\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "model=linear_regression(3,300)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader1:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "print('1st')\n",
    "test(model, optimizer, test_x1, test_y1)\n",
    "\n",
    "#2\n",
    "model=linear_regression(3,300)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader2:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('2nd')\n",
    "test(model, optimizer, test_x2, test_y2)\n",
    "     \n",
    "#3\n",
    "model=linear_regression(3,300)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader3:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('3rd')\n",
    "test(model, optimizer, test_x3, test_y3)\n",
    "\n",
    "#4\n",
    "model=linear_regression(3,300)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader4:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('4th')\n",
    "test(model, optimizer, test_x4, test_y4)\n",
    "\n",
    "#5\n",
    "model=linear_regression(3,300)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader5:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('5th')\n",
    "test(model, optimizer, test_x5, test_y5)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e55cd737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st\n",
      "mean cost:  0.41720542920171283\n",
      "2nd\n",
      "mean cost:  0.41586218659009316\n",
      "3rd\n",
      "mean cost:  0.41546833675995004\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30242/2784290463.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#1\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5, relu, linear6)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader1:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "print('1st')\n",
    "test(model, optimizer, test_x1, test_y1)\n",
    "\n",
    "#2\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5, relu, linear6)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader2:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('2nd')\n",
    "test(model, optimizer, test_x2, test_y2)\n",
    "     \n",
    "#3\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5, relu, linear6)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader3:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('3rd')\n",
    "test(model, optimizer, test_x3, test_y3)\n",
    "\n",
    "#4\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5, relu, linear6)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader4:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('4th')\n",
    "test(model, optimizer, test_x4, test_y4)\n",
    "\n",
    "#5\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5, relu, linear6)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader5:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('5th')\n",
    "test(model, optimizer, test_x5, test_y5)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e2f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
