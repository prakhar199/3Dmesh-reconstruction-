{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd70b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn,optim\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d70f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./samples/sample_data.json') as f:\n",
    "    x = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a52b6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'length_start': 3388, 'length_end': 3217, 'width_start': 3351, 'width_end': 3349, 'height_start': 3353, 'height_end': 3324}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from star.pytorch.star import STAR\n",
    "\n",
    "with open ('idx_data.txt', 'rb') as fr:\n",
    "    idx_data = pickle.load(fr)\n",
    "    \n",
    "print(idx_data)\n",
    "\n",
    "length_start_idx = idx_data['length_start']\n",
    "length_end_idx = idx_data['length_end']\n",
    "width_start_idx = idx_data['width_start']\n",
    "width_end_idx = idx_data['width_end']\n",
    "height_start_idx = idx_data['height_start']\n",
    "height_end_idx = idx_data['height_end']\n",
    "\n",
    "sample_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a91a158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30461/789766872.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_x2 = torch.tensor(train_x1)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30461/789766872.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_y2 = torch.tensor(train_y1).reshape(800,300)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30461/789766872.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_x2 = torch.tensor(test_x1)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30461/789766872.py:117: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_y2 = torch.tensor(test_y1).reshape(200,300)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30461/789766872.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_x3 = torch.tensor(train_x1)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30461/789766872.py:120: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_y3 = torch.tensor(train_y1).reshape(800,300)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30461/789766872.py:121: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_x3 = torch.tensor(test_x1)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30461/789766872.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_y3 = torch.tensor(test_y1).reshape(200,300)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30461/789766872.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_x4 = torch.tensor(train_x1)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30461/789766872.py:125: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_y4 = torch.tensor(train_y1).reshape(800,300)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30461/789766872.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_x4 = torch.tensor(test_x1)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30461/789766872.py:127: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_y4 = torch.tensor(test_y1).reshape(200,300)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30461/789766872.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_x5 = torch.tensor(train_x1)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30461/789766872.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_y5 = torch.tensor(train_y1).reshape(800,300)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30461/789766872.py:131: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_x5 = torch.tensor(test_x1)\n",
      "/var/folders/4t/46_77nfx56b601yby17b4g2c0000gn/T/ipykernel_30461/789766872.py:132: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_y5 = torch.tensor(test_y1).reshape(200,300)\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "train_x1 = []\n",
    "train_y1 = []\n",
    "test_x1 = []\n",
    "test_y1 = []\n",
    "\n",
    "train_x2 = []\n",
    "train_y2 = []\n",
    "test_x2 = []\n",
    "test_y2 = []\n",
    "\n",
    "train_x3 = []\n",
    "train_y3 = []\n",
    "test_x3 = []\n",
    "test_y3 = []\n",
    "\n",
    "train_x4 = []\n",
    "train_y4 = []\n",
    "test_x4 = []\n",
    "test_y4 = []\n",
    "\n",
    "train_x5 = []\n",
    "train_y5 = []\n",
    "test_x5 = []\n",
    "test_y5 = []\n",
    "\n",
    "for case in x:\n",
    "    if num < 200:\n",
    "        test_x1.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        test_y1.append(case['shape']) \n",
    "        \n",
    "        train_x2.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y2.append(case['shape']) \n",
    "        \n",
    "        train_x3.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y3.append(case['shape']) \n",
    "        \n",
    "        train_x4.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y4.append(case['shape']) \n",
    "        \n",
    "        train_x5.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y5.append(case['shape']) \n",
    "        \n",
    "    elif num < 400:\n",
    "        train_x1.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y1.append(case['shape'])  \n",
    "        \n",
    "        test_x2.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        test_y2.append(case['shape']) \n",
    "        \n",
    "        train_x3.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y3.append(case['shape']) \n",
    "        \n",
    "        train_x4.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y4.append(case['shape']) \n",
    "        \n",
    "        train_x5.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y5.append(case['shape']) \n",
    "        \n",
    "    elif num < 600:\n",
    "        train_x1.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y1.append(case['shape'])  \n",
    "        \n",
    "        train_x2.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y2.append(case['shape']) \n",
    "        \n",
    "        test_x3.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        test_y3.append(case['shape']) \n",
    "        \n",
    "        train_x4.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y4.append(case['shape']) \n",
    "        \n",
    "        train_x5.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y5.append(case['shape']) \n",
    "        \n",
    "    elif num < 800:\n",
    "        train_x1.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y1.append(case['shape']) \n",
    "        \n",
    "        train_x2.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y2.append(case['shape']) \n",
    "        \n",
    "        train_x3.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y3.append(case['shape']) \n",
    "        \n",
    "        test_x4.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        test_y4.append(case['shape']) \n",
    "        \n",
    "        train_x5.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y5.append(case['shape']) \n",
    "        \n",
    "    elif num < 1000:\n",
    "        train_x1.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y1.append(case['shape'])  \n",
    "        \n",
    "        train_x2.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y2.append(case['shape']) \n",
    "        \n",
    "        train_x3.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y3.append(case['shape']) \n",
    "        \n",
    "        train_x4.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        train_y4.append(case['shape']) \n",
    "        \n",
    "        test_x5.append([case['feature']['length'],case['feature']['width'],case['feature']['height']])\n",
    "        test_y5.append(case['shape']) \n",
    "    num+=1 \n",
    "\n",
    "train_x1 = torch.tensor(train_x1)\n",
    "train_y1 = torch.tensor(train_y1).reshape(800,300)\n",
    "test_x1 = torch.tensor(test_x1)\n",
    "test_y1 = torch.tensor(test_y1).reshape(200,300)\n",
    "\n",
    "train_x2 = torch.tensor(train_x1)\n",
    "train_y2 = torch.tensor(train_y1).reshape(800,300)\n",
    "test_x2 = torch.tensor(test_x1)\n",
    "test_y2 = torch.tensor(test_y1).reshape(200,300)\n",
    "\n",
    "train_x3 = torch.tensor(train_x1)\n",
    "train_y3 = torch.tensor(train_y1).reshape(800,300)\n",
    "test_x3 = torch.tensor(test_x1)\n",
    "test_y3 = torch.tensor(test_y1).reshape(200,300)\n",
    "\n",
    "train_x4 = torch.tensor(train_x1)\n",
    "train_y4 = torch.tensor(train_y1).reshape(800,300)\n",
    "test_x4 = torch.tensor(test_x1)\n",
    "test_y4 = torch.tensor(test_y1).reshape(200,300)\n",
    "\n",
    "train_x5 = torch.tensor(train_x1)\n",
    "train_y5 = torch.tensor(train_y1).reshape(800,300)\n",
    "test_x5 = torch.tensor(test_x1)\n",
    "test_y5 = torch.tensor(test_y1).reshape(200,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201b6987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Data1(Dataset):\n",
    "    def __init__(self):\n",
    "            self.x=train_x1\n",
    "            self.w=torch.zeros(3,300)\n",
    "            self.b=torch.zeros(800,300)\n",
    "            self.f=torch.mm(self.x,self.w)+self.b\n",
    "            \n",
    "            self.y=train_y1\n",
    "            self.len=self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "class Data2(Dataset):\n",
    "    def __init__(self):\n",
    "            self.x=train_x2\n",
    "            self.w=torch.zeros(3,300)\n",
    "            self.b=torch.zeros(800,300)\n",
    "            self.f=torch.mm(self.x,self.w)+self.b\n",
    "            \n",
    "            self.y=train_y2\n",
    "            self.len=self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "class Data3(Dataset):\n",
    "    def __init__(self):\n",
    "            self.x=train_x3\n",
    "            self.w=torch.zeros(3,300)\n",
    "            self.b=torch.zeros(800,300)\n",
    "            self.f=torch.mm(self.x,self.w)+self.b\n",
    "            \n",
    "            self.y=train_y3\n",
    "            self.len=self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "class Data4(Dataset):\n",
    "    def __init__(self):\n",
    "            self.x=train_x4\n",
    "            self.w=torch.zeros(3,300)\n",
    "            self.b=torch.zeros(800,300)\n",
    "            self.f=torch.mm(self.x,self.w)+self.b\n",
    "            \n",
    "            self.y=train_y4\n",
    "            self.len=self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "class Data5(Dataset):\n",
    "    def __init__(self):\n",
    "            self.x=train_x5\n",
    "            self.w=torch.zeros(3,300)\n",
    "            self.b=torch.zeros(800,300)\n",
    "            self.f=torch.mm(self.x,self.w)+self.b\n",
    "            \n",
    "            self.y=train_y5\n",
    "            self.len=self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cfe635a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_set=Data()'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''data_set=Data()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2884377",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_regression(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(linear_regression,self).__init__()\n",
    "        self.linear=nn.Linear(input_size,output_size)\n",
    "    def forward(self,x):\n",
    "        ythat=self.linear(x)\n",
    "        return ythat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "004fa47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = torch.nn.Linear(3,1000, bias = True)\n",
    "linear2 = torch.nn.Linear(1000,1000, bias = True)\n",
    "linear3 = torch.nn.Linear(1000,1000, bias = True)\n",
    "linear4 = torch.nn.Linear(1000,1000, bias = True)\n",
    "linear5 = torch.nn.Linear(1000,1000, bias = True)\n",
    "linear6 = torch.nn.Linear(1000,300, bias = True)\n",
    "relu = torch.nn.ReLU()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baaa6b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'optimizer = optim.SGD(model.parameters(), lr = 0.1)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''optimizer = optim.SGD(model.parameters(), lr = 0.1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8cd791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a306ead9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_loader=DataLoader(dataset=data_set,batch_size=1800, shuffle=True)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train_loader=DataLoader(dataset=data_set,batch_size=1800, shuffle=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15c5e00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LOSS=[]\\n \\nepochs=1000\\nfor epoch in range(epochs):\\n    for x,y in train_loader:\\n        prediction = model(x)\\n        #calculate loss        \\n        loss=criterion(prediction ,y)\\n        #store loss/cost \\n        LOSS.append(loss.item())\\n        #clear gradient \\n        optimizer.zero_grad()\\n        #Backward pass: compute gradient of the loss with respect to all the learnable parameters\\n        loss.backward()\\n        #the step function on an Optimizer makes an update to its parameters\\n        optimizer.step()\\n     \\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''LOSS=[]\n",
    " \n",
    "epochs=1000\n",
    "for epoch in range(epochs):\n",
    "    for x,y in train_loader:\n",
    "        prediction = model(x)\n",
    "        #calculate loss        \n",
    "        loss=criterion(prediction ,y)\n",
    "        #store loss/cost \n",
    "        LOSS.append(loss.item())\n",
    "        #clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        #Backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "        loss.backward()\n",
    "        #the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer.step()\n",
    "     \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc026509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plt.plot(LOSS)\\nplt.xlabel(\"iterations \")\\nplt.ylabel(\"Cost/total loss \")\\nplt.show()'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''plt.plot(LOSS)\n",
    "plt.xlabel(\"iterations \")\n",
    "plt.ylabel(\"Cost/total loss \")\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6870cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_betas = 300\n",
    "batch_size = 1\n",
    "poses = torch.FloatTensor(np.zeros((batch_size,72)))\n",
    "trans = torch.FloatTensor(np.zeros((batch_size,3)))\n",
    "\n",
    "def test(model, optimizer, x_test, y_test):\n",
    "    cost_sum_length = 0 \n",
    "    cost_sum_width = 0 \n",
    "    cost_sum_height = 0 \n",
    "    for x in x_test:\n",
    "        betas = model(x)\n",
    "        betas = torch.reshape(betas,(1,300))\n",
    "        mystar = STAR(gender='female',num_betas=num_betas)\n",
    "        mymodel = mystar.forward(poses , betas , trans)\n",
    "        shaped = mymodel.v_shaped[-1, :, :]\n",
    "\n",
    "        x_diff = shaped[3387][0]\n",
    "        y_diff = shaped[3387][1]\n",
    "        z_diff = shaped[3387][2]\n",
    "\n",
    "        length = (shaped[length_end_idx-1][2]-shaped[length_start_idx-1][2]).item()\n",
    "        width = (shaped[width_end_idx-1][0]-shaped[width_start_idx-1][0]).item()\n",
    "        height = (shaped[height_end_idx-1][1]-shaped[height_start_idx-1][1]).item()\n",
    "\n",
    "        prediction = torch.tensor([length, width, height])\n",
    "        \n",
    "        cost_length = criterion(prediction[0]*100, x[0]*100)\n",
    "        cost_sum_length += cost_length.item()\n",
    "        cost_width = criterion(prediction[1]*100, x[1]*100)\n",
    "        cost_sum_width += cost_width.item()\n",
    "        cost_height = criterion(prediction[2]*100, x[2]*100)\n",
    "        cost_sum_height += cost_height.item()\n",
    "    print('length' , cost_sum_length / len(x_test))\n",
    "    print('width' , cost_sum_width / len(x_test))\n",
    "    print('height' , cost_sum_height / len(x_test))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "005c3509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test(model, optimizer, test_x, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ece3265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader1=DataLoader(dataset=Data1(),batch_size=1800, shuffle=True)\n",
    "train_loader2=DataLoader(dataset=Data2(),batch_size=1800, shuffle=True)\n",
    "train_loader3=DataLoader(dataset=Data3(),batch_size=1800, shuffle=True)\n",
    "train_loader4=DataLoader(dataset=Data4(),batch_size=1800, shuffle=True)\n",
    "train_loader5=DataLoader(dataset=Data5(),batch_size=1800, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de3f4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_betas = 300\n",
    "batch_size = 1\n",
    "poses = torch.FloatTensor(np.zeros((batch_size,72)))\n",
    "trans = torch.FloatTensor(np.zeros((batch_size,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bad47062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st\n",
      "length 0.8746010889156787\n",
      "width 0.1739497003197539\n",
      "height 0.2327629703769071\n",
      "2nd\n",
      "length 0.8394529936668187\n",
      "width 0.1795229183639458\n",
      "height 0.2530503132784952\n",
      "3rd\n",
      "length 0.8406629137182972\n",
      "width 0.17360648966533518\n",
      "height 0.2332726189636378\n",
      "4th\n",
      "length 0.8153276569888294\n",
      "width 0.17255262829950424\n",
      "height 0.22940077335759723\n",
      "5th\n",
      "length 0.8327991509302592\n",
      "width 0.188615150570281\n",
      "height 0.23675529422447653\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "model=linear_regression(3,300)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader1:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "print('1st')\n",
    "test(model, optimizer, test_x1, test_y1)\n",
    "\n",
    "#2\n",
    "model=linear_regression(3,300)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader2:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('2nd')\n",
    "test(model, optimizer, test_x2, test_y2)\n",
    "     \n",
    "#3\n",
    "model=linear_regression(3,300)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader3:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('3rd')\n",
    "test(model, optimizer, test_x3, test_y3)\n",
    "\n",
    "#4\n",
    "model=linear_regression(3,300)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader4:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('4th')\n",
    "test(model, optimizer, test_x4, test_y4)\n",
    "\n",
    "#5\n",
    "model=linear_regression(3,300)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader5:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('5th')\n",
    "test(model, optimizer, test_x5, test_y5)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e55cd737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#1\\nmodel = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5, relu, linear6)\\noptimizer = optim.SGD(model.parameters(), lr = 0.1)\\nfor epoch in range(1000):\\n    for x,y in train_loader1:\\n        prediction = model(x)       \\n        loss=criterion(prediction ,y)\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n        \\nprint('1st')\\ntest(model, optimizer, test_x1, test_y1)\\n\\n#2\\nmodel = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5, relu, linear6)\\noptimizer = optim.SGD(model.parameters(), lr = 0.1)\\nfor epoch in range(1000):\\n    for x,y in train_loader2:\\n        prediction = model(x)       \\n        loss=criterion(prediction ,y)\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n\\nprint('2nd')\\ntest(model, optimizer, test_x2, test_y2)\\n     \\n#3\\nmodel = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5, relu, linear6)\\noptimizer = optim.SGD(model.parameters(), lr = 0.1)\\nfor epoch in range(1000):\\n    for x,y in train_loader3:\\n        prediction = model(x)       \\n        loss=criterion(prediction ,y)\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n\\nprint('3rd')\\ntest(model, optimizer, test_x3, test_y3)\\n\\n#4\\nmodel = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5, relu, linear6)\\noptimizer = optim.SGD(model.parameters(), lr = 0.1)\\nfor epoch in range(1000):\\n    for x,y in train_loader4:\\n        prediction = model(x)       \\n        loss=criterion(prediction ,y)\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n\\nprint('4th')\\ntest(model, optimizer, test_x4, test_y4)\\n\\n#5\\nmodel = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5, relu, linear6)\\noptimizer = optim.SGD(model.parameters(), lr = 0.1)\\nfor epoch in range(1000):\\n    for x,y in train_loader5:\\n        prediction = model(x)       \\n        loss=criterion(prediction ,y)\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n\\nprint('5th')\\ntest(model, optimizer, test_x5, test_y5)\\n           \""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#1\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5, relu, linear6)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader1:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "print('1st')\n",
    "test(model, optimizer, test_x1, test_y1)\n",
    "\n",
    "#2\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5, relu, linear6)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader2:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('2nd')\n",
    "test(model, optimizer, test_x2, test_y2)\n",
    "     \n",
    "#3\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5, relu, linear6)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader3:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('3rd')\n",
    "test(model, optimizer, test_x3, test_y3)\n",
    "\n",
    "#4\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5, relu, linear6)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader4:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('4th')\n",
    "test(model, optimizer, test_x4, test_y4)\n",
    "\n",
    "#5\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5, relu, linear6)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(1000):\n",
    "    for x,y in train_loader5:\n",
    "        prediction = model(x)       \n",
    "        loss=criterion(prediction ,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('5th')\n",
    "test(model, optimizer, test_x5, test_y5)\n",
    "           '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e2f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
